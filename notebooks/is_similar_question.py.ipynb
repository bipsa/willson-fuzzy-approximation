{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tag import TrigramTagger, UnigramTagger\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "Hola como estás el día de hoy? Cómo voy a estar mañana?\n",
      "????? <UnigramTagger: size=7386>\n",
      "['Hola', 'día', 'hoy']\n",
      "????? <UnigramTagger: size=7386>\n",
      "['Cómo', 'voy', 'mañana']\n"
     ]
    }
   ],
   "source": [
    "test1 = ['hola', 'como', 'estoy']\n",
    "test2 = ['hola', 'como', 'estoy', 'hoy']\n",
    "\n",
    "ratio = len(set(test1).intersection(test2)) / float(len(set(test1).union(test2)))\n",
    "print(ratio)\n",
    "\n",
    "class Question:\n",
    "    \n",
    "    def __init__(self, question, language='spanish'):\n",
    "        self.question = question\n",
    "        self.language = language\n",
    "        self.stopwords = None\n",
    "        self.defaultTagger = None\n",
    "        \n",
    "    def get_stop_words(self):\n",
    "        if not self.stopwords:\n",
    "            self.stopwords = nltk.corpus.stopwords.words(self.language)\n",
    "            self.stopwords.extend(string.punctuation)\n",
    "            self.stopwords.append('')\n",
    "        return self.stopwords\n",
    "    \n",
    "    def get_tagger(self):\n",
    "        if not self.defaultTagger:\n",
    "            tagged_sents = cess_esp.tagged_sents()\n",
    "            spanish_text = cess_esp.tagged_sents()\n",
    "            train_sents = spanish_text[:3000]\n",
    "            test_sents = spanish_text[3000:]\n",
    "            default_tagger = nltk.DefaultTagger('nc')\n",
    "            affix_tagger = nltk.AffixTagger(tagged_sents, backoff=default_tagger)\n",
    "            self.defaultTagger = UnigramTagger(train_sents, cutoff=0, backoff=affix_tagger)\n",
    "        return self.defaultTagger\n",
    "        \n",
    "    def normalize(self, text):\n",
    "        self.get_stop_words()\n",
    "        tagger = self.get_tagger()\n",
    "        print('?????', tagger)\n",
    "        tokens = word_tokenize(text)\n",
    "        text_tokenized = []\n",
    "        for word in tokens:\n",
    "            if word not in self.stopwords:\n",
    "                text_tokenized.append(word)\n",
    "        print(text_tokenized)\n",
    "        \n",
    "    \n",
    "    def is_similar(self, text):\n",
    "        print(self.question, text)\n",
    "        self.normalize(self.question)\n",
    "        self.normalize(text)\n",
    "\n",
    "question = Question('Hola como estás el día de hoy?')\n",
    "question.is_similar('Cómo voy a estar mañana?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
